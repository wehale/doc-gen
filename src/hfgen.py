import huggingface_hub as hf
import glob
import jsonlines as jsonl
import time

MAX_TOKENS = 2000 # maximum number of tokens to generate

class HuggingFaceGenerator:

    LOG_PREFIX = "[hfai-gen]>"

    def __init__(self, args, key, config):
        self._args = args
        self._key = key
        self._config = config
        self._model = self._config['hfllm']['model']
        self._files = glob.glob(self._config['input']['path']+"/*")
        self._prompts_file_str = self._config['hfllm']['prompts']
        self._client = hf.InferenceClient(token=self._key)

    def generate(self) -> dict:
        print(f"{self._config['hfllm']['name']} is generating...")
        stats = {self._config['hfllm']['description_prefix']: {}}
        for f in self._files:
            t1 = time.time()
            input_file = open(f, 'r')
            input_file_split = f.split("/")
            input_file_name = input_file_split[len(input_file_split)-1]
            output_file_name = self._config['hfllm']['gen_file_prefix'] + input_file_split[len(input_file_split)-1].split(".")[0] + ".md"
            open(self._config['output']['path']+"/"+output_file_name, 'w').close() #clear output file
            output_file = open(self._config['output']['path']+"/"+output_file_name, 'a') # append the output file
            output_file.write("\n" + "# "+ self._config['hfllm']['description_prefix'] + ": " + input_file_name + "\n")
            code_file_str_for_prompt = "Consider the following code between the markers <start_code> and <end_code>\n\n<start_code>\n\n" \
                + input_file.read() + "\n\n<end_code>\n\n"
            ps = jsonl.open(self._prompts_file_str)
            for prompt in ps:
                message = code_file_str_for_prompt + prompt['description']
                response = self._client.chat_completion(messages=[{"role": "user", "content": message}], max_tokens=MAX_TOKENS)
                output_file.write("\n" + "## "+ prompt['title']+ ": " + input_file_name + "\n")
                print(self.LOG_PREFIX + response.choices[0].message.content)
                output_file.write(response.choices[0].message.content)
                output_file.write("\n")
                output_file.write("\n" + "(Generated by "+ self._config['author'] + 
                            " using " + self._config['hfllm']['name'] + " " + 
                            self._config['hfllm']['model'] +")\n")
            input_file.close()
            output_file.close()
            t2 = time.time()
            stats[self._config['hfllm']['description_prefix']][input_file_name] = t2-t1
        return stats
